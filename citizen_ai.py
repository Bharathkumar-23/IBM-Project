# -*- coding: utf-8 -*-
"""Citizen AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juI2EGvONnVkIooqiXXhiIouTpsrDaJj
"""

!pip install transformers torch gradio -q

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Load model and tokenizer
model_name = "ibm-granite/granite-3.2-2b-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# Core LLM Response Generator
def generate_response(prompt, max_length=1024):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    if torch.cuda.is_available():
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = response.replace(prompt, "").strip()
    return response

# ================= Functions for Tabs =================
def city_analysis(city_name):
    prompt = f"Provide a detailed analysis of {city_name} including:\n1. Crime Index and safety statistics\n2. Accident rates and traffic safety information\n3. Emergency services availability\n4. Overall safety assessment\n\nCity: {city_name}\nAnalysis:"
    return generate_response(prompt, max_length=1000)

def citizen_interaction(query):
    prompt = f"As a government assistant, provide accurate and helpful information about the following citizen query related to public services, government policies, or civic issues:\n\nQuery: {query}\nResponse:"
    return generate_response(prompt, max_length=1000)

def emergency_services(city_name):
    prompt = f"List the major emergency services in {city_name}, including:\n- Nearest hospitals\n- Police stations\n- Fire stations\n- Emergency helplines\n\nCity: {city_name}\nServices:"
    return generate_response(prompt, max_length=800)

def policy_explainer(policy_name):
    prompt = f"Explain the government policy '{policy_name}' in simple terms. Include:\n1. Objective of the policy\n2. Who it benefits\n3. Key rules or eligibility\n4. Real-life impact on citizens\n\nPolicy: {policy_name}\nExplanation:"
    return generate_response(prompt, max_length=1000)

def citizen_feedback(feedback_text):
    prompt = f"Summarize the following citizen feedback in a neutral and professional tone. Highlight the main concerns and suggestions:\n\nFeedback: {feedback_text}\nSummary:"
    return generate_response(prompt, max_length=600)

# ================= Gradio UI =================
with gr.Blocks(theme="default") as app:
    gr.Markdown("# üèôÔ∏è City & Citizen AI Portal")
    gr.Markdown("This AI-powered assistant provides **city safety analysis, emergency service info, policy explainers, and citizen support.**")

    with gr.Tabs():
        # --- Tab 1: City Analysis ---
        with gr.TabItem("üìä City Analysis"):
            with gr.Row():
                city_input = gr.Textbox(label="Enter City Name", placeholder="e.g., New York, London, Mumbai...", lines=1)
                analyze_btn = gr.Button("üîç Analyze City")
                clear_city = gr.Button("Clear")
            city_output = gr.Textbox(label="City Analysis", lines=15)
            analyze_btn.click(city_analysis, inputs=city_input, outputs=city_output)
            clear_city.click(lambda: "", None, city_output)

        # --- Tab 2: Citizen Services ---
        with gr.TabItem("üë• Citizen Services"):
            with gr.Row():
                citizen_query = gr.Textbox(label="Your Query", placeholder="Ask about public services, policies, civic issues...", lines=4)
                query_btn = gr.Button("Get Info")
                clear_citizen = gr.Button("Clear")
            citizen_output = gr.Textbox(label="Government Response", lines=15)
            query_btn.click(citizen_interaction, inputs=citizen_query, outputs=citizen_output)
            clear_citizen.click(lambda: "", None, citizen_output)

        # --- Tab 3: Emergency Services ---
        with gr.TabItem("üö® Emergency Services"):
            with gr.Row():
                city_service_input = gr.Textbox(label="Enter City Name", placeholder="e.g., Delhi, Paris, Tokyo...", lines=1)
                service_btn = gr.Button("Find Services")
                clear_services = gr.Button("Clear")
            service_output = gr.Textbox(label="Emergency Services Information", lines=12)
            service_btn.click(emergency_services, inputs=city_service_input, outputs=service_output)
            clear_services.click(lambda: "", None, service_output)

        # --- Tab 4: Policy Explainer ---
        with gr.TabItem("üìú Policy Explainer"):
            with gr.Row():
                policy_input = gr.Textbox(label="Policy Name", placeholder="e.g., Right to Education Act, Digital India, Clean Air Policy...", lines=1)
                policy_btn = gr.Button("Explain Policy")
                clear_policy = gr.Button("Clear")
            policy_output = gr.Textbox(label="Policy Explanation", lines=15)
            policy_btn.click(policy_explainer, inputs=policy_input, outputs=policy_output)
            clear_policy.click(lambda: "", None, policy_output)

        # --- Tab 5: Citizen Feedback Hub ---
        with gr.TabItem("üìù Citizen Feedback"):
            with gr.Row():
                feedback_input = gr.Textbox(label="Your Feedback", placeholder="Write your concerns or suggestions...", lines=5)
                feedback_btn = gr.Button("Summarize Feedback")
                clear_feedback = gr.Button("Clear")
            feedback_output = gr.Textbox(label="Feedback Summary", lines=10)
            feedback_btn.click(citizen_feedback, inputs=feedback_input, outputs=feedback_output)
            clear_feedback.click(lambda: "", None, feedback_output)

# Launch app
app.launch(share=True)